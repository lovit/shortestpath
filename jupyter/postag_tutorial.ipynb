{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lovit.github.io/nlp/graph/2017/08/21/ford_for_pos/ 의 예시코드 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = '청하는 아이오아이의 출신입니다'\n",
    "\n",
    "pos2words = {\n",
    "    'Noun': set('아이 아이오 아이오아이 청하 출신 청'.split()),\n",
    "    'Josa': set('은 는 이 가 의 를 을'.split()),\n",
    "    'Verb': set('청하 이 있 하 했 입'.split()),\n",
    "    'Eomi': set('다 었다 는 니다'.split())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "    def __init__(self, pos2words=None):\n",
    "        self.pos2words = pos2words if pos2words else {}\n",
    "        self.max_len = self._set_max_len()\n",
    "\n",
    "    def _set_max_len(self):\n",
    "        if not self.pos2words: return 0\n",
    "        return max((len(word) for words in self.pos2words.values() for word in words))\n",
    "\n",
    "    def get_pos(self, word):\n",
    "        return [pos for pos, words in self.pos2words.items() if word in words]\n",
    "\n",
    "dictionary = Dictionary(pos2words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Josa', 'Verb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.get_pos('이')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noun', 'Verb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.get_pos('청하')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('청', 'Noun', 0, 1), ('청하', 'Noun', 0, 2), ('청하', 'Verb', 0, 2)],\n",
       " [('하', 'Verb', 1, 2)],\n",
       " [('는', 'Josa', 2, 3), ('는', 'Eomi', 2, 3)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_lookup(eojeol, offset):\n",
    "    n = len(eojeol)\n",
    "    words = [[] for _ in range(n)]\n",
    "    for b in range(n):\n",
    "        for r in range(1, dictionary.max_len+1):\n",
    "            e = b+r\n",
    "            if e > n:\n",
    "                continue\n",
    "            sub = eojeol[b:e]\n",
    "            for pos in dictionary.get_pos(sub):\n",
    "                words[b].append((sub, pos, b+offset, e+offset))\n",
    "    return words\n",
    "\n",
    "word_lookup('청하는', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('청', 'Noun', 3, 4), ('청하', 'Noun', 3, 5), ('청하', 'Verb', 3, 5)],\n",
       " [('하', 'Verb', 4, 5)],\n",
       " [('는', 'Josa', 5, 6), ('는', 'Eomi', 5, 6)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lookup('청하는', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('청', 'Noun', 0, 1), ('청하', 'Noun', 0, 2), ('청하', 'Verb', 0, 2)],\n",
       " [('하', 'Verb', 1, 2)],\n",
       " [('는', 'Josa', 2, 3), ('는', 'Eomi', 2, 3)],\n",
       " [('아이', 'Noun', 3, 5), ('아이오', 'Noun', 3, 6), ('아이오아이', 'Noun', 3, 8)],\n",
       " [('이', 'Josa', 4, 5), ('이', 'Verb', 4, 5)],\n",
       " [],\n",
       " [('아이', 'Noun', 6, 8)],\n",
       " [('이', 'Josa', 7, 8), ('이', 'Verb', 7, 8)],\n",
       " [('의', 'Josa', 8, 9)],\n",
       " [('출신', 'Noun', 9, 11)],\n",
       " [],\n",
       " [('입', 'Verb', 11, 12)],\n",
       " [('니다', 'Eomi', 12, 14)],\n",
       " [('다', 'Eomi', 13, 14)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lookup(sentence):\n",
    "    sent = []\n",
    "    for eojeol in sentence.split():\n",
    "        sent += word_lookup(eojeol, offset=len(sent))\n",
    "    return sent\n",
    "\n",
    "lookup(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_edges(sentence):\n",
    "    chars = sentence.replace(' ', '')\n",
    "    sent = lookup(sentence)\n",
    "    n_char = len(chars)\n",
    "    sent.append([('EOS', 'EOS', n_char + 1, n_char + 1)])\n",
    "\n",
    "    nonempty_first = get_nonempty_first(sent, offset=0)\n",
    "    if nonempty_first > 0:\n",
    "        sent[0].append((chars[:nonempty_first], 'Unk', 0, nonempty_first))\n",
    "\n",
    "    edges = forward_link(sent, chars)\n",
    "    edges = backward_link_for_unk(edges, sent)\n",
    "    edges = add_bos(edges, sent)\n",
    "\n",
    "    edges = sorted(edges, key=lambda x:(x[0][2], x[0][3], x[1][2]))\n",
    "    return edges, sent\n",
    "\n",
    "def forward_link(sent, chars):\n",
    "    edges = []\n",
    "    for words in sent[:-1]:\n",
    "        for word in words:\n",
    "            begin = word[2]\n",
    "            end = word[3]\n",
    "            if not sent[end]:\n",
    "                next_begin = get_nonempty_first(sent, end)\n",
    "                unk = (chars[end:next_begin], 'Unk', end, next_begin)\n",
    "                edges.append((word, unk))\n",
    "            else:\n",
    "                for adjacent in sent[end]:\n",
    "                    edges.append((word, adjacent))\n",
    "    return edges\n",
    "\n",
    "def backward_link_for_unk(edges, sent):\n",
    "    unks = {node for _, node in edges if node[1] == 'Unk'}\n",
    "    for unk in unks:\n",
    "        for adjacent in sent[unk[3]]:\n",
    "            edges.append((unk, adjacent))\n",
    "    return edges\n",
    "\n",
    "def add_bos(edges, sent):\n",
    "    bos = ('BOS', 'BOS', 0, 0)\n",
    "    for word in sent[0]:\n",
    "        edges.append((bos, word))\n",
    "    return edges\n",
    "\n",
    "def get_nonempty_first(sent, offset=0):\n",
    "    for i in range(offset, len(sent)+1):\n",
    "        if sent[i]:\n",
    "            return i\n",
    "    return offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges, sent = draw_edges(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('청', 'Noun', 0, 1), ('청하', 'Noun', 0, 2), ('청하', 'Verb', 0, 2)],\n",
       " [('하', 'Verb', 1, 2)],\n",
       " [('는', 'Josa', 2, 3), ('는', 'Eomi', 2, 3)],\n",
       " [('아이', 'Noun', 3, 5), ('아이오', 'Noun', 3, 6), ('아이오아이', 'Noun', 3, 8)],\n",
       " [('이', 'Josa', 4, 5), ('이', 'Verb', 4, 5)],\n",
       " [],\n",
       " [('아이', 'Noun', 6, 8)],\n",
       " [('이', 'Josa', 7, 8), ('이', 'Verb', 7, 8)],\n",
       " [('의', 'Josa', 8, 9)],\n",
       " [('출신', 'Noun', 9, 11)],\n",
       " [],\n",
       " [('입', 'Verb', 11, 12)],\n",
       " [('니다', 'Eomi', 12, 14)],\n",
       " [('다', 'Eomi', 13, 14)],\n",
       " [('EOS', 'EOS', 15, 15)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('BOS', 'BOS', 0, 0), ('청', 'Noun', 0, 1)),\n",
       " (('BOS', 'BOS', 0, 0), ('청하', 'Noun', 0, 2)),\n",
       " (('BOS', 'BOS', 0, 0), ('청하', 'Verb', 0, 2)),\n",
       " (('청', 'Noun', 0, 1), ('하', 'Verb', 1, 2)),\n",
       " (('청하', 'Noun', 0, 2), ('는', 'Josa', 2, 3)),\n",
       " (('청하', 'Noun', 0, 2), ('는', 'Eomi', 2, 3)),\n",
       " (('청하', 'Verb', 0, 2), ('는', 'Josa', 2, 3)),\n",
       " (('청하', 'Verb', 0, 2), ('는', 'Eomi', 2, 3)),\n",
       " (('하', 'Verb', 1, 2), ('는', 'Josa', 2, 3)),\n",
       " (('하', 'Verb', 1, 2), ('는', 'Eomi', 2, 3)),\n",
       " (('는', 'Josa', 2, 3), ('아이', 'Noun', 3, 5)),\n",
       " (('는', 'Josa', 2, 3), ('아이오', 'Noun', 3, 6)),\n",
       " (('는', 'Josa', 2, 3), ('아이오아이', 'Noun', 3, 8)),\n",
       " (('는', 'Eomi', 2, 3), ('아이', 'Noun', 3, 5)),\n",
       " (('는', 'Eomi', 2, 3), ('아이오', 'Noun', 3, 6)),\n",
       " (('는', 'Eomi', 2, 3), ('아이오아이', 'Noun', 3, 8)),\n",
       " (('아이', 'Noun', 3, 5), ('오', 'Unk', 5, 6)),\n",
       " (('아이오', 'Noun', 3, 6), ('아이', 'Noun', 6, 8)),\n",
       " (('아이오아이', 'Noun', 3, 8), ('의', 'Josa', 8, 9)),\n",
       " (('이', 'Josa', 4, 5), ('오', 'Unk', 5, 6)),\n",
       " (('이', 'Verb', 4, 5), ('오', 'Unk', 5, 6)),\n",
       " (('오', 'Unk', 5, 6), ('아이', 'Noun', 6, 8)),\n",
       " (('아이', 'Noun', 6, 8), ('의', 'Josa', 8, 9)),\n",
       " (('이', 'Josa', 7, 8), ('의', 'Josa', 8, 9)),\n",
       " (('이', 'Verb', 7, 8), ('의', 'Josa', 8, 9)),\n",
       " (('의', 'Josa', 8, 9), ('출신', 'Noun', 9, 11)),\n",
       " (('출신', 'Noun', 9, 11), ('입', 'Verb', 11, 12)),\n",
       " (('입', 'Verb', 11, 12), ('니다', 'Eomi', 12, 14)),\n",
       " (('니다', 'Eomi', 12, 14), ('EOS', 'EOS', 15, 15)),\n",
       " (('다', 'Eomi', 13, 14), ('EOS', 'EOS', 15, 15))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition = {\n",
    "    ('Noun', 'Josa'): 0.7,\n",
    "    ('Noun', 'Noun'): 0.3,\n",
    "    ('Verb', 'Eomi'): 0.5,\n",
    "    ('Verb', 'Noun'): 0.5,\n",
    "    ('Verb', 'Josa'): -0.1,\n",
    "}\n",
    "generation = {\n",
    "    'Noun': {\n",
    "        '아이오아이': 0.5,\n",
    "        '청하': 0.2,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Weighter:\n",
    "    def __init__(self, transition, generation):\n",
    "        self.transition = transition\n",
    "        self.generation = generation\n",
    "\n",
    "    def cost(self, edge):\n",
    "        prob = 0\n",
    "        prob += self.transition.get((edge[0][1], edge[1][1]), 0)\n",
    "        for node in edge:\n",
    "            prob += self.generation.get(node[1], {}).get(node[0], 0)\n",
    "        return -1 * prob\n",
    "\n",
    "weighter = Weighter(transition, generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('청하', 'Noun', 0, 2), ('는', 'Josa', 2, 3))\n",
      "-0.8999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(edges[4])\n",
    "print(weighter.cost(edges[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('BOS', 'BOS', 0, 0), ('청', 'Noun', 0, 1), 0),\n",
       " (('BOS', 'BOS', 0, 0), ('청하', 'Noun', 0, 2), -0.2),\n",
       " (('BOS', 'BOS', 0, 0), ('청하', 'Verb', 0, 2), 0),\n",
       " (('청', 'Noun', 0, 1), ('하', 'Verb', 1, 2), 0),\n",
       " (('청하', 'Noun', 0, 2), ('는', 'Josa', 2, 3), -0.8999999999999999),\n",
       " (('청하', 'Noun', 0, 2), ('는', 'Eomi', 2, 3), -0.2),\n",
       " (('청하', 'Verb', 0, 2), ('는', 'Josa', 2, 3), 0.1),\n",
       " (('청하', 'Verb', 0, 2), ('는', 'Eomi', 2, 3), -0.5),\n",
       " (('하', 'Verb', 1, 2), ('는', 'Josa', 2, 3), 0.1),\n",
       " (('하', 'Verb', 1, 2), ('는', 'Eomi', 2, 3), -0.5),\n",
       " (('는', 'Josa', 2, 3), ('아이', 'Noun', 3, 5), 0),\n",
       " (('는', 'Josa', 2, 3), ('아이오', 'Noun', 3, 6), 0),\n",
       " (('는', 'Josa', 2, 3), ('아이오아이', 'Noun', 3, 8), -0.5),\n",
       " (('는', 'Eomi', 2, 3), ('아이', 'Noun', 3, 5), 0),\n",
       " (('는', 'Eomi', 2, 3), ('아이오', 'Noun', 3, 6), 0),\n",
       " (('는', 'Eomi', 2, 3), ('아이오아이', 'Noun', 3, 8), -0.5),\n",
       " (('아이', 'Noun', 3, 5), ('오', 'Unk', 5, 6), 0),\n",
       " (('아이오', 'Noun', 3, 6), ('아이', 'Noun', 6, 8), -0.3),\n",
       " (('아이오아이', 'Noun', 3, 8), ('의', 'Josa', 8, 9), -1.2),\n",
       " (('이', 'Josa', 4, 5), ('오', 'Unk', 5, 6), 0),\n",
       " (('이', 'Verb', 4, 5), ('오', 'Unk', 5, 6), 0),\n",
       " (('오', 'Unk', 5, 6), ('아이', 'Noun', 6, 8), 0),\n",
       " (('아이', 'Noun', 6, 8), ('의', 'Josa', 8, 9), -0.7),\n",
       " (('이', 'Josa', 7, 8), ('의', 'Josa', 8, 9), 0),\n",
       " (('이', 'Verb', 7, 8), ('의', 'Josa', 8, 9), 0.1),\n",
       " (('의', 'Josa', 8, 9), ('출신', 'Noun', 9, 11), 0),\n",
       " (('출신', 'Noun', 9, 11), ('입', 'Verb', 11, 12), 0),\n",
       " (('입', 'Verb', 11, 12), ('니다', 'Eomi', 12, 14), -0.5),\n",
       " (('니다', 'Eomi', 12, 14), ('EOS', 'EOS', 15, 15), 0),\n",
       " (('다', 'Eomi', 13, 14), ('EOS', 'EOS', 15, 15), 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attach_weight(edges):\n",
    "    edges = [(edge[0], edge[1], weighter.cost(edge)) for edge in edges]\n",
    "    return edges\n",
    "\n",
    "edges = attach_weight(edges)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('BOS', 'BOS', 0, 0): {('청', 'Noun', 0, 1): 0,\n",
      "                        ('청하', 'Noun', 0, 2): -0.2,\n",
      "                        ('청하', 'Verb', 0, 2): 0},\n",
      " ('는', 'Eomi', 2, 3): {('아이', 'Noun', 3, 5): 0,\n",
      "                       ('아이오', 'Noun', 3, 6): 0,\n",
      "                       ('아이오아이', 'Noun', 3, 8): -0.5},\n",
      " ('는', 'Josa', 2, 3): {('아이', 'Noun', 3, 5): 0,\n",
      "                       ('아이오', 'Noun', 3, 6): 0,\n",
      "                       ('아이오아이', 'Noun', 3, 8): -0.5},\n",
      " ('니다', 'Eomi', 12, 14): {('EOS', 'EOS', 15, 15): 0},\n",
      " ('다', 'Eomi', 13, 14): {('EOS', 'EOS', 15, 15): 0},\n",
      " ('아이', 'Noun', 3, 5): {('오', 'Unk', 5, 6): 0},\n",
      " ('아이', 'Noun', 6, 8): {('의', 'Josa', 8, 9): -0.7},\n",
      " ('아이오', 'Noun', 3, 6): {('아이', 'Noun', 6, 8): -0.3},\n",
      " ('아이오아이', 'Noun', 3, 8): {('의', 'Josa', 8, 9): -1.2},\n",
      " ('오', 'Unk', 5, 6): {('아이', 'Noun', 6, 8): 0},\n",
      " ('의', 'Josa', 8, 9): {('출신', 'Noun', 9, 11): 0},\n",
      " ('이', 'Josa', 4, 5): {('오', 'Unk', 5, 6): 0},\n",
      " ('이', 'Josa', 7, 8): {('의', 'Josa', 8, 9): 0},\n",
      " ('이', 'Verb', 4, 5): {('오', 'Unk', 5, 6): 0},\n",
      " ('이', 'Verb', 7, 8): {('의', 'Josa', 8, 9): 0.1},\n",
      " ('입', 'Verb', 11, 12): {('니다', 'Eomi', 12, 14): -0.5},\n",
      " ('청', 'Noun', 0, 1): {('하', 'Verb', 1, 2): 0},\n",
      " ('청하', 'Noun', 0, 2): {('는', 'Eomi', 2, 3): -0.2,\n",
      "                        ('는', 'Josa', 2, 3): -0.8999999999999999},\n",
      " ('청하', 'Verb', 0, 2): {('는', 'Eomi', 2, 3): -0.5, ('는', 'Josa', 2, 3): 0.1},\n",
      " ('출신', 'Noun', 9, 11): {('입', 'Verb', 11, 12): 0},\n",
      " ('하', 'Verb', 1, 2): {('는', 'Eomi', 2, 3): -0.5, ('는', 'Josa', 2, 3): 0.1}}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "def edges_to_dict(edges):\n",
    "    g = defaultdict(lambda: {})\n",
    "    for from_, to_, weight in edges:\n",
    "        g[from_][to_] = weight\n",
    "    return dict(g)\n",
    "\n",
    "g = edges_to_dict(edges)\n",
    "pprint(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from shortestpath import ford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost[('BOS', 'BOS', 0, 0) -> ('청', 'Noun', 0, 1)] = 24.200000000000003 -> 0\n",
      "cost[('BOS', 'BOS', 0, 0) -> ('청하', 'Noun', 0, 2)] = 24.200000000000003 -> -0.2\n",
      "cost[('BOS', 'BOS', 0, 0) -> ('청하', 'Verb', 0, 2)] = 24.200000000000003 -> 0\n",
      "cost[('청', 'Noun', 0, 1) -> ('하', 'Verb', 1, 2)] = 24.200000000000003 -> 0\n",
      "cost[('청하', 'Noun', 0, 2) -> ('는', 'Josa', 2, 3)] = 24.200000000000003 -> -1.0999999999999999\n",
      "cost[('청하', 'Noun', 0, 2) -> ('는', 'Eomi', 2, 3)] = 24.200000000000003 -> -0.4\n",
      "cost[('청하', 'Verb', 0, 2) -> ('는', 'Eomi', 2, 3)] = -0.4 -> -0.5\n",
      "cost[('는', 'Josa', 2, 3) -> ('아이', 'Noun', 3, 5)] = 24.200000000000003 -> -1.0999999999999999\n",
      "cost[('는', 'Josa', 2, 3) -> ('아이오', 'Noun', 3, 6)] = 24.200000000000003 -> -1.0999999999999999\n",
      "cost[('는', 'Josa', 2, 3) -> ('아이오아이', 'Noun', 3, 8)] = 24.200000000000003 -> -1.5999999999999999\n",
      "cost[('아이', 'Noun', 3, 5) -> ('오', 'Unk', 5, 6)] = 24.200000000000003 -> -1.0999999999999999\n",
      "cost[('아이오', 'Noun', 3, 6) -> ('아이', 'Noun', 6, 8)] = 24.200000000000003 -> -1.4\n",
      "cost[('아이오아이', 'Noun', 3, 8) -> ('의', 'Josa', 8, 9)] = 24.200000000000003 -> -2.8\n",
      "cost[('의', 'Josa', 8, 9) -> ('출신', 'Noun', 9, 11)] = 24.200000000000003 -> -2.8\n",
      "cost[('출신', 'Noun', 9, 11) -> ('입', 'Verb', 11, 12)] = 24.200000000000003 -> -2.8\n",
      "cost[('입', 'Verb', 11, 12) -> ('니다', 'Eomi', 12, 14)] = 24.200000000000003 -> -3.3\n",
      "cost[('니다', 'Eomi', 12, 14) -> ('EOS', 'EOS', 15, 15)] = 24.200000000000003 -> -3.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cost': -3.3,\n",
       " 'paths': [[('BOS', 'BOS', 0, 0),\n",
       "   ('청하', 'Noun', 0, 2),\n",
       "   ('는', 'Josa', 2, 3),\n",
       "   ('아이오아이', 'Noun', 3, 8),\n",
       "   ('의', 'Josa', 8, 9),\n",
       "   ('출신', 'Noun', 9, 11),\n",
       "   ('입', 'Verb', 11, 12),\n",
       "   ('니다', 'Eomi', 12, 14),\n",
       "   ('EOS', 'EOS', 15, 15)]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos = ('BOS', 'BOS', 0, 0)\n",
    "eos = ('EOS', 'EOS', 15, 15)\n",
    "ford(g, bos, eos, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
